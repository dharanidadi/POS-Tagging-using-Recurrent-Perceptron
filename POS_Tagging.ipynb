{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CQFVP9MAIPRA",
        "q40z2WVpIWCo",
        "FKxyapfmKyQB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFyVJf2aWLE4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "class RecurrentPerceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.01):\n",
        "        self.input_size = input_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Initialize weights\n",
        "        self.W_in = np.random.randn(1, input_size)\n",
        "        self.W_rec = np.random.randn(1, 1)\n",
        "\n",
        "        # Initialize bias\n",
        "        self.b_hidden = np.zeros((1, 1))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def forward(self, x):\n",
        "        T = len(x)\n",
        "        # print(T, type(x), x[0])\n",
        "\n",
        "        self.hidden_states = np.zeros((T+1, 1, 1))\n",
        "        self.outputs = np.zeros((T, 1, 1))\n",
        "\n",
        "        for t in range(T):\n",
        "            # Update hidden state\n",
        "            self.hidden_states[t+1] = self.sigmoid(np.dot(self.W_in, x[t]) + np.dot(self.W_rec, self.hidden_states[t]) + self.b_hidden)\n",
        "            # print(self.hidden_states[t+1,0,0])\n",
        "            # Output is same as hidden state\n",
        "            self.outputs[t] = self.hidden_states[t+1]\n",
        "\n",
        "        return self.outputs.flatten()\n",
        "\n",
        "    def backward(self, x, y, outputs):\n",
        "        # print(outputs,y)\n",
        "        T = len(x)\n",
        "        dW_in = np.zeros_like(self.W_in)\n",
        "        dW_rec = np.zeros_like(self.W_rec)\n",
        "        db_hidden = np.zeros_like(self.b_hidden)\n",
        "        dh, dhnext = 0, 0\n",
        "\n",
        "        delta_out = outputs - y\n",
        "\n",
        "        for t in range(T-1, -1, -1):\n",
        "            # Backpropagate through time\n",
        "            delta_hidden = delta_out[t]\n",
        "            sum_win = 0\n",
        "            sum_wrec = 0\n",
        "            for i in range(t,-1,-1):\n",
        "              if i < t-50:\n",
        "                break\n",
        "              sum_win += x[i].T*(self.W_rec**(t-i))\n",
        "              if i == t:\n",
        "                continue\n",
        "              sum_wrec += outputs[i]*(self.W_rec**(t-i-1))\n",
        "\n",
        "            # Update input layer weights\n",
        "            dW_in += (delta_hidden*sum_win)/T\n",
        "            # Update hidden layer recurrent weights\n",
        "            dW_rec += (delta_hidden*sum_wrec)/T\n",
        "            # Update hidden layer bias\n",
        "            db_hidden += delta_hidden/T\n",
        "\n",
        "        # Clip gradients to prevent explosion\n",
        "        clip_value = 1\n",
        "        dW_in = np.clip(dW_in, -clip_value, clip_value)\n",
        "        dW_rec = np.clip(dW_rec, -clip_value, clip_value)\n",
        "        db_hidden = np.clip(db_hidden, -clip_value, clip_value)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.W_in -= self.learning_rate * dW_in\n",
        "        self.W_rec -= self.learning_rate * dW_rec\n",
        "        self.b_hidden -= self.learning_rate * db_hidden\n",
        "\n",
        "    def train(self, x_train, y_train, epochs, print_losses = True):\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            for x, y in zip(x_train, y_train):\n",
        "                outputs = self.forward(x)\n",
        "                loss = self.cross_entropy_loss(outputs, y)\n",
        "                total_loss += loss\n",
        "                self.backward(x, y, outputs)\n",
        "            if print_losses == False:\n",
        "              continue\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/14041}\")\n",
        "            # print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/5000}\")\n",
        "\n",
        "    def cross_entropy_loss(self, outputs, y):\n",
        "        # print(outputs.shape, y.shape)\n",
        "        eps = 1e-10  # Small constant to prevent log(0)\n",
        "        loss = -np.sum(y * np.log(outputs + eps) + (1 - y) * np.log(1 - outputs + eps))\n",
        "        return loss\n",
        "\n",
        "    def get_weights(self):\n",
        "      return self.W_in, self.W_rec, self.b_hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Training Data"
      ],
      "metadata": {
        "id": "CQFVP9MAIPRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data from JSONL file\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "# l = 0\n",
        "with open('train.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "        # l += 1\n",
        "        # if l == 5000:\n",
        "        #   break\n",
        "        data = json.loads(line)\n",
        "        tokens = data[\"tokens\"]\n",
        "        pos_tags = data[\"pos_tags\"]\n",
        "        chunk_tags = data[\"chunk_tags\"]\n",
        "\n",
        "        # Add start of sentence tag at the beginning of each sentence\n",
        "        pos_tags.insert(0, 0)  # Assuming start of sentence tag is represented by 0\n",
        "\n",
        "        sentence_x = []\n",
        "        sentence_y = []\n",
        "\n",
        "        for i in range(len(tokens)):\n",
        "            current_pos = pos_tags[i + 1]  # Adjust index to start from 1\n",
        "            previous_pos = pos_tags[i] if i > 0 else 0  # Assuming start of sentence token is represented by 0\n",
        "\n",
        "            # One-hot encode current and previous POS tags\n",
        "            current_pos_one_hot = np.zeros((4, 1))\n",
        "            current_pos_one_hot[current_pos - 1] = 1  # Adjust index to start from 0\n",
        "            previous_pos_one_hot = np.zeros((5, 1))\n",
        "            previous_pos_one_hot[previous_pos] = 1\n",
        "\n",
        "            # Concatenate current and previous POS tags as input\n",
        "            # input_data = np.vstack((current_pos_one_hot, previous_pos_one_hot))\n",
        "            input_data = np.vstack((previous_pos_one_hot, current_pos_one_hot))\n",
        "            sentence_x.append(input_data)\n",
        "\n",
        "            # Append corresponding chunk tag as output\n",
        "            sentence_y.append(chunk_tags[i])\n",
        "\n",
        "        sentence_x = np.array(sentence_x)\n",
        "        sentence_y = np.array(sentence_y)\n",
        "        x_train.append(sentence_x)\n",
        "        y_train.append(sentence_y)"
      ],
      "metadata": {
        "id": "QWYgVF0LISuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Testing Data"
      ],
      "metadata": {
        "id": "q40z2WVpIWCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data from JSONL file\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "with open('test.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        tokens = data[\"tokens\"]\n",
        "        pos_tags = data[\"pos_tags\"]\n",
        "        chunk_tags = data[\"chunk_tags\"]\n",
        "\n",
        "        # Add start of sentence tag at the beginning of each sentence\n",
        "        pos_tags.insert(0, 0)  # Assuming start of sentence tag is represented by 0\n",
        "\n",
        "        sentence_x = []\n",
        "        sentence_y = []\n",
        "\n",
        "        for i in range(len(tokens)):\n",
        "            current_pos = pos_tags[i + 1]  # Adjust index to start from 1\n",
        "            previous_pos = pos_tags[i] if i > 0 else 0  # Assuming start of sentence token is represented by 0\n",
        "\n",
        "            # One-hot encode current and previous POS tags\n",
        "            current_pos_one_hot = np.zeros((4, 1))\n",
        "            current_pos_one_hot[current_pos - 1] = 1  # Adjust index to start from 0\n",
        "            previous_pos_one_hot = np.zeros((5, 1))\n",
        "            previous_pos_one_hot[previous_pos] = 1\n",
        "\n",
        "            # Concatenate current and previous POS tags as input\n",
        "            # input_data = np.vstack((current_pos_one_hot, previous_pos_one_hot))\n",
        "            input_data = np.vstack((previous_pos_one_hot, current_pos_one_hot))\n",
        "            sentence_x.append(input_data)\n",
        "\n",
        "            # Append corresponding chunk tag as output\n",
        "            sentence_y.append(chunk_tags[i])\n",
        "\n",
        "        sentence_x = np.array(sentence_x)\n",
        "        sentence_y = np.array(sentence_y)\n",
        "        x_test.append(sentence_x)\n",
        "        y_test.append(sentence_y)"
      ],
      "metadata": {
        "id": "m2tXehVtIaTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model"
      ],
      "metadata": {
        "id": "d3IY3paJIlo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the recurrent perceptron\n",
        "np.random.seed(10)\n",
        "rnn = RecurrentPerceptron(input_size=9, learning_rate=0.01)\n",
        "rnn.train(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOw7I8YiIn-T",
        "outputId": "c1a6e998-5ddd-4e83-ade1-837c3192380a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 6.166726348172704\n",
            "Epoch 2/5, Loss: 5.890635589818979\n",
            "Epoch 3/5, Loss: 5.84594660296437\n",
            "Epoch 4/5, Loss: 5.821079545573299\n",
            "Epoch 5/5, Loss: 5.806947265177464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "def evaluate(model, x_test, y_test):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x, y in zip(x_test, y_test):\n",
        "        outputs = model.forward(x)\n",
        "        predictions = (outputs >= 0.5).astype(int)  # Convert outputs to binary predictions\n",
        "        correct += np.sum(predictions == y)\n",
        "        total += len(y)\n",
        "        # total += 1\n",
        "        # if False in (predictions == y):\n",
        "        #   continue\n",
        "        # correct += 1\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy = evaluate(rnn, x_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUg4BUhhIukb",
        "outputId": "2b0e05d2-d637-47c8-e076-f0c815d91ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8371056315279423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test data\n",
        "predictions = []\n",
        "for x in x_test:\n",
        "    outputs = rnn.forward(x)\n",
        "    predictions.append(outputs)\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "predictions_binary = [np.array(p) > 0.5 for p in predictions]\n",
        "\n",
        "# Flatten y_test for sklearn metrics\n",
        "y_test_flat = np.concatenate(y_test)\n",
        "predictions_flat = np.concatenate(predictions_binary)\n",
        "\n",
        "# Calculate precision, recall, f1 score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test_flat, predictions_flat, average='binary')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_flat, predictions_flat)\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_flat, predictions_flat)\n",
        "\n",
        "# Extract true positives, false positives, true negatives, false negatives\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)\n",
        "print(\"Total Test Accuracy:\", accuracy)\n",
        "print(\"Accuracy Class-1:\", tp/(tp+fn))\n",
        "print(\"Accuracy Class-0:\", tn/(tn+fp))\n",
        "print(\"True positives:\", tp, \", False positives:\", fp, \", True negatives:\", tn, \", False negatives:\", fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTlYZ-LWJDOm",
        "outputId": "3808f2b2-8ed3-4d02-b003-1558b232dca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8120050593928728\n",
            "Recall: 0.9759732963183291\n",
            "F1 Score: 0.886470747155765\n",
            "Total Test Accuracy: 0.8371056315279423\n",
            "Accuracy Class-1: 0.9759732963183291\n",
            "Accuracy Class-0: 0.5773629226679854\n",
            "True positives: 29531 , False positives: 6837 , True negatives: 9340 , False negatives: 727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weights satisfying conditions"
      ],
      "metadata": {
        "id": "4qyI7M5gkeXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Win, Wrec, b = rnn.get_weights()"
      ],
      "metadata": {
        "id": "gzD8k5iLUl2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Win, Wrec, b"
      ],
      "metadata": {
        "id": "hIPjjIAXn7ix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc843da-010d-4734-c6d6-bb23d2b7e7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 5.09518762, -0.73548008, -1.37135318, -1.30932991,  1.09020914,\n",
              "         -1.13124588,  2.13834087, -0.34739816,  0.84361143]]),\n",
              " array([[-1.00297167]]),\n",
              " array([[1.04960552]]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_conditions(W, V, thresh=0.5) :\n",
        "        # w = [w^, w_nn_prev, w_dt_prev, w_jj_prev, w_ot_prev, w_nn, w_dt, w_jj, w_ot]\n",
        "      conditions = [\n",
        "      W[0] + W[-3] >= thresh,\n",
        "      W[0] + W[-2] >= thresh,\n",
        "      W[0] + W[-4] >= thresh,\n",
        "      W[0] + W[-1] >= thresh,\n",
        "      V + W[2] + W[-2] <= thresh,\n",
        "      V + W[2] + W[-4] <= thresh,\n",
        "      W[3] + W[-2] <= thresh,\n",
        "      W[3] + W[-4] <= thresh,\n",
        "      V + W[3] + W[-2] <= thresh,\n",
        "      V + W[3] + W[-4] <= thresh,\n",
        "      W[1] + W[-1] >= thresh,\n",
        "      V + W[1] + W[-1] >= thresh,\n",
        "      V + W[4] + W[-3] >= thresh,\n",
        "      V + W[4] + W[-2] >= thresh,\n",
        "      V + W[4] + W[-4] >= thresh,\n",
        "      V + W[4] + W[-1] >= thresh]\n",
        "\n",
        "      false_cond = []\n",
        "\n",
        "      for i, c in enumerate(conditions):\n",
        "        if c == False:\n",
        "          false_cond.append(i)\n",
        "\n",
        "      if false_cond == []:\n",
        "        print(\"All conditions satisfied\")\n",
        "      else:\n",
        "        for j in false_cond:\n",
        "          print(\"Condition\", j, \"is false\")\n",
        "\n",
        "      return"
      ],
      "metadata": {
        "id": "h8V0-cEPoDKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_conditions(Win.flatten(), Wrec[0,0], -b)"
      ],
      "metadata": {
        "id": "qGDIqO-5uIt2",
        "outputId": "29d9a414-cae3-4f54-a85b-d23b4c846c6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All conditions satisfied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 Fold Cross Validation"
      ],
      "metadata": {
        "id": "zikdI0lOKuHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
        "i = 0\n",
        "\n",
        "for train_index, val_index in kf.split(x_train):\n",
        "    print(f'Split {i+1}')\n",
        "    # print(len(train_index))\n",
        "    x_train_fold = [x_train[i] for i in train_index]\n",
        "    y_train_fold = [y_train[i] for i in train_index]\n",
        "    x_val_fold = [x_train[i] for i in val_index]\n",
        "    y_val_fold = [y_train[i] for i in val_index]\n",
        "\n",
        "    # Create and train the recurrent perceptron\n",
        "    rnn = RecurrentPerceptron(input_size=9, learning_rate=0.1)\n",
        "    rnn.train(x_train_fold, y_train_fold, epochs=5, print_losses = False)\n",
        "\n",
        "    # Make predictions on validation data\n",
        "    predictions = []\n",
        "    for x in x_val_fold:\n",
        "        outputs = rnn.forward(x)\n",
        "        predictions.append(outputs)\n",
        "\n",
        "    # Convert predictions to binary (0 or 1)\n",
        "    predictions_binary = [np.array(p) > 0.5 for p in predictions]\n",
        "\n",
        "    # Flatten y_val_fold for sklearn metrics\n",
        "    y_val_flat = np.concatenate(y_val_fold)\n",
        "    predictions_flat = np.concatenate(predictions_binary)\n",
        "\n",
        "    # Calculate precision, recall, f1 score\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_val_flat, predictions_flat, average='binary')\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_val_flat, predictions_flat)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_val_flat, predictions_flat)\n",
        "\n",
        "    # Extract true positives, false positives, true negatives, false negatives\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "    # Calculate accuracy of class 0 and class 1\n",
        "    accuracy_class_0 = tn / (tn + fp) if tn + fp > 0 else 0\n",
        "    accuracy_class_1 = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "\n",
        "\n",
        "    print('Precision:', precision)\n",
        "    print('Recall:', recall)\n",
        "    print('F1 Score:', f1_score)\n",
        "    print('Total Accuracy:', accuracy)\n",
        "    print('Accuracy Class-0:', accuracy_class_0)\n",
        "    print('Accuracy Class-1:', accuracy_class_1)\n",
        "    print('True Positives:', tp, ', False Positives:', fp, ', True Negatives:', tn, ', False Negatives:', fn)\n",
        "    print()\n",
        "\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fScpWGruq51d",
        "outputId": "56b0a505-3bae-427c-c855-bb744700e2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split 1\n",
            "Precision: 0.5326494150193073\n",
            "Recall: 0.47097793405697397\n",
            "F1 Score: 0.4999188619029588\n",
            "Total Accuracy: 0.37634916351861847\n",
            "Accuracy Class-0: 0.1911221945137157\n",
            "Accuracy Class-1: 0.47097793405697397\n",
            "True Positives: 9242 , False Positives: 8109 , True Negatives: 1916 , False Negatives: 10381\n",
            "\n",
            "Split 2\n",
            "Precision: 0.747615136774275\n",
            "Recall: 0.5966522133709792\n",
            "F1 Score: 0.6636570114684688\n",
            "Total Accuracy: 0.5980497285704711\n",
            "Accuracy Class-0: 0.6008193445243805\n",
            "Accuracy Class-1: 0.5966522133709792\n",
            "True Positives: 11834 , False Positives: 3995 , True Negatives: 6013 , False Negatives: 8000\n",
            "\n",
            "Split 3\n",
            "Precision: 0.7745789995047053\n",
            "Recall: 0.6412937618535035\n",
            "F1 Score: 0.7016628810184796\n",
            "Total Accuracy: 0.6341220166448862\n",
            "Accuracy Class-0: 0.6195004702685756\n",
            "Accuracy Class-1: 0.6412937618535035\n",
            "True Positives: 12511 , False Positives: 3641 , True Negatives: 5928 , False Negatives: 6998\n",
            "\n",
            "Split 4\n",
            "Precision: 0.8062553000448945\n",
            "Recall: 0.8158186957399556\n",
            "F1 Score: 0.8110088060412957\n",
            "Total Accuracy: 0.7443754453832842\n",
            "Accuracy Class-0: 0.5978047012529771\n",
            "Accuracy Class-1: 0.8158186957399556\n",
            "True Positives: 16163 , False Positives: 3884 , True Negatives: 5773 , False Negatives: 3649\n",
            "\n",
            "Split 5\n",
            "Precision: 0.8719262959839097\n",
            "Recall: 0.7095939595543588\n",
            "F1 Score: 0.7824289706567302\n",
            "Total Accuracy: 0.7376899589372828\n",
            "Accuracy Class-0: 0.7933849696462215\n",
            "Accuracy Class-1: 0.7095939595543588\n",
            "True Positives: 13439 , False Positives: 1974 , True Negatives: 7580 , False Negatives: 5500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GUI"
      ],
      "metadata": {
        "id": "OdKGi_cTO4cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "bX6TL0DdO6WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "# Define the function to predict chunk tags for custom inputs\n",
        "def predict_chunk_tags_custom(pos_tags):\n",
        "    # Assuming the input string contains space-separated integers\n",
        "    pos_tags = list(map(int, pos_tags.split()))\n",
        "\n",
        "    sentence_x = []\n",
        "\n",
        "    for i in range(len(pos_tags)):\n",
        "        current_pos = pos_tags[i]\n",
        "        previous_pos = pos_tags[i - 1] if i > 0 else 0\n",
        "\n",
        "        current_pos_one_hot = np.zeros((4, 1))\n",
        "        current_pos_one_hot[current_pos - 1] = 1\n",
        "        previous_pos_one_hot = np.zeros((5, 1))\n",
        "        previous_pos_one_hot[previous_pos] = 1\n",
        "\n",
        "        input_data = np.vstack((previous_pos_one_hot, current_pos_one_hot))\n",
        "        sentence_x.append(input_data)\n",
        "\n",
        "    sentence_x = np.array(sentence_x)\n",
        "    outputs = rnn.forward(sentence_x)\n",
        "    predictions = (outputs >= 0.5).astype(int)\n",
        "    predicted_chunk_tags = \"\".join(map(str, predictions))\n",
        "\n",
        "    return predicted_chunk_tags\n",
        "\n",
        "gr.Interface(\n",
        "    predict_chunk_tags_custom,\n",
        "    inputs= gr.Textbox(label=\"Enter POS tags (space-separated)\"),\n",
        "    outputs= gr.Text(label=\"Predicted Chunk Tags\")\n",
        ").launch(debug=False)\n"
      ],
      "metadata": {
        "id": "_xgFzHBkPDtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EvKzIVZxiVPP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}